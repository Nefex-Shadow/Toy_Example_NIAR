{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af1e1f6-b567-4f24-aa8e-a6158d51db13",
   "metadata": {},
   "source": [
    "# Implementação 1: Toy Example\n",
    "\n",
    "Esse notebook apresenta a primeira implementação do Toy Example proposto.\n",
    "Sua proposta segue os seguintes objetivos:\n",
    "* A implementação não seguirá padrões sugeridos nos campos das dimensões da IAR.\n",
    "* Esse notebook servirá de checagem para análise da eficiência e corretude da checklist proposta pelo NIAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b39fc0-539f-4a0c-ad51-ed489ebb4ae2",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "Os dados são de origem do Datasus, contendo informações das internações nos períodos de 2022 à novembro de 2025 (dados mais recentes quando feito esse Toy Example).\n",
    "\n",
    "Devido ao tamanho dos dados brutos, não se encontram na página do Github. No entanto, a tabela final (após todo o pré processamento) se encontra em \"Tabela_lag_final.zip\". Apenas essa tabela é necessária para a execução do notebook. Para tal, descomprima o arquivo zip e coloque o arquivo \"Tabela_lag_final.csv\" (o único arquivo csv) dentro do diretório \"SIH_Dados/\".\n",
    "\n",
    "O download dos dados foi feito por conexão ftp com o servidor disponibilizado pelo datasus: ftp.datasus.gov.br. Especificamente, os dados se encontram no diretório \"/dissemin/publicos/SIHSUS/200801_/Dados/\". Foram usados todos os arquivos que começam com \"RD\" e contém \"22\", \"23\", \"24\", \"25\", no quinto e sexto caractére (quando escrito esse notebook, exclui-se os dados de dezembro de 2025 e os dados de novembro de 2025 dos estados \"AC\" e \"RR\", pois não foram divulgados ainda).\n",
    "\n",
    "A fim de evitar refazer grandes cálculos toda vez que esse notebook é executado, o processamento dos dados - filtragem de colunas de interesse e cálculo de novas colunas - foi feito previamente. No diretório SIH_Dados, encontram-se os scripts usados para cada etapa do processamento:\n",
    "* dbc_dbf.py e dbf_csv.py: Transformam os arquivos de dados do formato dbc para dbf e dbf para csv, respectivamente.\n",
    "* filtrar.py: Lê os arquivos csv, filtram as colunas (e o \"target\" de interesse, DIAG_PRIN = \"J...\") e salvam em novos csv.\n",
    "* tabelacao_agregado.py: Lê os novos arquivos csv, e calcula os valores agregados dos dados, agrupando-os por mes/ano e hospital. A tabela resultante é salva em \"Tabela_Agregada.csv\".\n",
    "* tabelacao_lag_final.py: Lê a tabelacao do passo anterior e calcula as variaveis \"lag\", usadas no modelo para predicao. A tabela, com todos os atributos que serão usados para o modelo final, é salva em um último csv: \"Tabela_lag_Final.csv\".\n",
    "\n",
    "O intuito de separar cada processo em seu próprio script é devido a robustez contra a possibilidade de erros ou mudanças, permitindo que alterações sejam feitas sem a necessidade de recomeçar o processo do zero. Além disso, cada script demora vários minutos, alguns até passando de uma hora, para terminar. Juntar todos os scripts em um resultaria em um programa que terminaria após várias horas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd0268-7db7-448d-a5ee-e40440c9c6cd",
   "metadata": {},
   "source": [
    "### Etapa 1: Inicialização\n",
    "Import's usados, e leitura dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0fa30c-029e-4d05-8aad-4cfbd895268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn as sk\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./SIH_Dados/Tabela_lag_Final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51caa17-0c36-4d1a-87cc-8aa44e6c128c",
   "metadata": {},
   "source": [
    "### Etapa 2: Limpagem e separação dos dados\n",
    "Retirada de linhas com dados nulos e separação dos dados de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9856233-1da1-41d1-9efc-be67aed04b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X_Train = df[(df.year >= 2022) & (df.year <= 2024)]\n",
    "X_Train = X_Train[(X_Train.year < 2024) | (X_Train.month <= 6)].reset_index(drop=True)\n",
    "Y_Train = X_Train[\"J_count\"]\n",
    "X_Train.drop(columns=\"J_count\", inplace=True)\n",
    "\n",
    "X_Valid = df[(df.year == 2024) & (df.month >= 7)].reset_index(drop=True)\n",
    "Y_Valid = X_Valid[\"J_count\"]\n",
    "X_Valid.drop(columns=\"J_count\", inplace=True)\n",
    "\n",
    "X_Test = df[df.year == 2025].reset_index(drop=True)\n",
    "Y_Test = X_Test[\"J_count\"]\n",
    "X_Test.drop(columns=\"J_count\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2f793-2e1c-4d64-96fc-f3bae4a46b9b",
   "metadata": {},
   "source": [
    "### Etapa 3: Modelo Base\n",
    "Testes usando modelo de Regressão Binomial Negativa, implementada pelo statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf18618-c6f7-453c-8424-7767045eac4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Retirada de colunas com valor único\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# X_Train.drop(columns=[c for c in X_Train.columns if X_Train[c].nunique() == 1], inplace=True)\u001b[39;00m\n\u001b[32m      4\u001b[39m model = sm.NegativeBinomial(Y_Train, X_Train)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(res.summary())\n\u001b[32m      8\u001b[39m val_resul = model.predict(params=res.params, exog=X_Valid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:3729\u001b[39m, in \u001b[36mNegativeBinomial.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, callback, cov_type, cov_kwds, use_t, optim_kwds_prelim, **kwargs)\u001b[39m\n\u001b[32m   3727\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m   3728\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33malways\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3729\u001b[39m     res_poi = \u001b[43mmod_poi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds_prelim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3730\u001b[39m start_params = res_poi.params\n\u001b[32m   3731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loglike_method.startswith(\u001b[33m'\u001b[39m\u001b[33mnb\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:1355\u001b[39m, in \u001b[36mPoisson.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m     kwds[\u001b[33m'\u001b[39m\u001b[33mcov_type\u001b[39m\u001b[33m'\u001b[39m] = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mcov_type\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1353\u001b[39m     kwds[\u001b[33m'\u001b[39m\u001b[33mcov_kwds\u001b[39m\u001b[33m'\u001b[39m] = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mcov_kwds\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m cntfit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCountModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1363\u001b[39m discretefit = PoissonResults(\u001b[38;5;28mself\u001b[39m, cntfit, **kwds)\n\u001b[32m   1364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PoissonResultsWrapper(discretefit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[39m, in \u001b[36mDiscreteModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m mlefit = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m                     \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/base/model.py:566\u001b[39m, in \u001b[36mLikelihoodModel.fit\u001b[39m\u001b[34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_t\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    565\u001b[39m optimizer = Optimizer()\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m xopt, retvals, optim_settings = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[32m    576\u001b[39m optim_settings.update(kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:245\u001b[39m, in \u001b[36mOptimizer._fit\u001b[39m\u001b[34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[39m\n\u001b[32m    242\u001b[39m     fit_funcs.update(extra_fit_funcs)\n\u001b[32m    244\u001b[39m func = fit_funcs[method]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m xopt, retvals = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m optim_settings = {\u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m: method, \u001b[33m'\u001b[39m\u001b[33mstart_params\u001b[39m\u001b[33m'\u001b[39m: start_params,\n\u001b[32m    251\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mmaxiter\u001b[39m\u001b[33m'\u001b[39m: maxiter, \u001b[33m'\u001b[39m\u001b[33mfull_output\u001b[39m\u001b[33m'\u001b[39m: full_output,\n\u001b[32m    252\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m: disp, \u001b[33m'\u001b[39m\u001b[33mfargs\u001b[39m\u001b[33m'\u001b[39m: fargs, \u001b[33m'\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m'\u001b[39m: callback,\n\u001b[32m    253\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33mretall\u001b[39m\u001b[33m'\u001b[39m: retall, \u001b[33m\"\u001b[39m\u001b[33mextra_fit_funcs\u001b[39m\u001b[33m\"\u001b[39m: extra_fit_funcs}\n\u001b[32m    254\u001b[39m optim_settings.update(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:450\u001b[39m, in \u001b[36m_fit_newton\u001b[39m\u001b[34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess, ridge_factor)\u001b[39m\n\u001b[32m    448\u001b[39m     H[np.diag_indices(H.shape[\u001b[32m0\u001b[39m])] += ridge_factor\n\u001b[32m    449\u001b[39m oldparams = newparams\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m newparams = oldparams - \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43moldparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retall:\n\u001b[32m    452\u001b[39m     history.append(newparams)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:452\u001b[39m, in \u001b[36msolve\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m    449\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mDD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdd->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    451\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     r = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Prog/NIAR/Toy_Example/venv/lib/python3.12/site-packages/numpy/linalg/_linalg.py:145\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retirada de colunas com valor único\n",
    "# X_Train.drop(columns=[c for c in X_Train.columns if X_Train[c].nunique() == 1], inplace=True)\n",
    "\n",
    "model = sm.NegativeBinomial(Y_Train, X_Train)\n",
    "res = model.fit()\n",
    "print(res.summary())\n",
    "\n",
    "val_resul = model.predict(params=res.params, exog=X_Valid)\n",
    "test_resul = model.predict(params=res.params, exog=X_Test)\n",
    "\n",
    "print(val_resul)\n",
    "print(test_resul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6141b-5337-4cc7-96b5-795de2706c27",
   "metadata": {},
   "source": [
    "### Etapa 4: Modelo LightGBM\n",
    "\n",
    "Testes usando modelo com objetivo Poisson, implementada pelo lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb854e33-d5cc-4308-863a-352b5892d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 778\n",
    "\n",
    "lgb_train = lgb.Dataset(X_Train, Y_Train)\n",
    "lgb_valid = lgb.Dataset(X_Valid, Y_Valid)\n",
    "\n",
    "\n",
    "\n",
    "model = lgb.train(params={\"objective\": \"poisson\"}, train_set=lgb_train, valid_sets=lgb_valid, callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "\n",
    "res_pred = model.predict(X_Test, num_iteration=model.best_iteration)\n",
    "print(len(res_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a299c-d35d-4b29-a5b1-7407fc26bf8f",
   "metadata": {},
   "source": [
    "### Etapa 5: Métricas\n",
    "\n",
    "Comparação dos resultados de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5194fb-b451-4d06-a533-dd8ab3d9ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = X_Test[[\"month\", \"CNES\"]]\n",
    "df_resultados[\"year\"] = 2025\n",
    "df_resultados = df_resultados[[\"year\", \"month\", \"CNES\"]]\n",
    "df_resultados[\"Valor Real\"] = Y_Test\n",
    "df_resultados[\"Base results\"] = test_resul\n",
    "df_resultados[\"LightGBM results\"] = res_pred\n",
    "\n",
    "# TEMPORARIO ==============\n",
    "test_resul = np.nan_to_num(test_resul, nan=0, copy=True)\n",
    "print(test_resul)\n",
    "\n",
    "base_mae = mean_absolute_error(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_mae = mean_absolute_error(y_true=Y_Test, y_pred=res_pred)\n",
    "\n",
    "\n",
    "base_rmse = mean_squared_error(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_rmse = mean_squared_error(y_true=Y_Test, y_pred=res_pred)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "base_smape = smape(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_smape = smape(y_true=Y_Test, y_pred=res_pred)\n",
    "\n",
    "print(df_resultados)\n",
    "print(\"------------------------------ RESULTADOS GLOBAIS ------------------------------\")\n",
    "print(\"\\t\\t\\t|\\t\\t\\t\\t|\")\n",
    "print(\"\\tMetrica\\t\\t|\\t\\tBase\\t\\t|\\tLightGBM\")\n",
    "print(\"------------------------+-------------------------------+-----------------------\")\n",
    "print(\"MAE\\t\\t\\t|\", base_mae, \"\\t\\t|\", lgb_mae)\n",
    "print(\"\\t\\t\\t|\\t\\t\\t\\t|\")\n",
    "print(\"RMSE\\t\\t\\t|\", base_rmse, \"\\t\\t|\", lgb_rmse)\n",
    "print(\"\\t\\t\\t|\\t\\t\\t\\t|\")\n",
    "print(\"SMAPE\\t\\t\\t|\", base_smape, \"\\t\\t\\t|\", lgb_smape)\n",
    "print(\"\\t\\t\\t|\\t\\t\\t\\t|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1772e-e85a-4934-beeb-cdcf1c1b98f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
