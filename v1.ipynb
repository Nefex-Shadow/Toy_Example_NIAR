{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af1e1f6-b567-4f24-aa8e-a6158d51db13",
   "metadata": {},
   "source": [
    "# Implementação 1: Toy Example\n",
    "\n",
    "Esse notebook apresenta a primeira implementação do Toy Example proposto.\n",
    "Sua proposta segue os seguintes objetivos:\n",
    "* A implementação não seguirá padrões sugeridos nos campos das dimensões da IAR.\n",
    "* Esse notebook servirá de checagem para análise da eficiência e corretude da checklist proposta pelo NIAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b39fc0-539f-4a0c-ad51-ed489ebb4ae2",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "Os dados são de origem do Datasus, contendo informações das internações nos períodos de 2022 à novembro de 2025 (dados mais recentes quando feito esse Toy Example).\n",
    "\n",
    "Devido ao tamanho dos dados brutos, não se encontram na página do Github. No entanto, a tabela final (após todo o pré processamento) se encontra em \"Tabela_lag_final.zip\". Apenas essa tabela é necessária para a execução do notebook. Para tal, descomprima o arquivo zip e coloque o arquivo \"Tabela_lag_final.csv\" (o único arquivo csv) dentro do diretório \"SIH_Dados/\".\n",
    "\n",
    "O download dos dados foi feito por conexão ftp com o servidor disponibilizado pelo datasus: ftp.datasus.gov.br. Especificamente, os dados se encontram no diretório \"/dissemin/publicos/SIHSUS/200801_/Dados/\". Foram usados todos os arquivos que começam com \"RD\" e contém \"22\", \"23\", \"24\", \"25\", no quinto e sexto caractére (quando escrito esse notebook, exclui-se os dados de dezembro de 2025 e os dados de novembro de 2025 dos estados \"AC\" e \"RR\", pois não foram divulgados ainda).\n",
    "\n",
    "A fim de evitar refazer grandes cálculos toda vez que esse notebook é executado, o processamento dos dados - filtragem de colunas de interesse e cálculo de novas colunas - foi feito previamente. No diretório SIH_Dados, encontram-se os scripts usados para cada etapa do processamento:\n",
    "* dbc_dbf.py e dbf_csv.py: Transformam os arquivos de dados do formato dbc para dbf e dbf para csv, respectivamente.\n",
    "* filtrar.py: Lê os arquivos csv, filtram as colunas (e o \"target\" de interesse, DIAG_PRIN = \"J...\") e salvam em novos csv.\n",
    "* tabelacao_agregado.py: Lê os novos arquivos csv, e calcula os valores agregados dos dados, agrupando-os por mes/ano e hospital. A tabela resultante é salva em \"Tabela_Agregada.csv\".\n",
    "* tabelacao_lag_final.py: Lê a tabelacao do passo anterior e calcula as variaveis \"lag\", usadas no modelo para predicao. A tabela, com todos os atributos que serão usados para o modelo final, é salva em um último csv: \"Tabela_lag_Final.csv\".\n",
    "\n",
    "O intuito de separar cada processo em seu próprio script é devido a robustez contra a possibilidade de erros ou mudanças, permitindo que alterações sejam feitas sem a necessidade de recomeçar o processo do zero. Além disso, cada script demora vários minutos, alguns até passando de uma hora, para terminar. Juntar todos os scripts em um resultaria em um programa que terminaria após várias horas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd0268-7db7-448d-a5ee-e40440c9c6cd",
   "metadata": {},
   "source": [
    "### Etapa 1: Inicialização\n",
    "Import's usados, e leitura dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0fa30c-029e-4d05-8aad-4cfbd895268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./SIH_Dados/Tabela_lag_Final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51caa17-0c36-4d1a-87cc-8aa44e6c128c",
   "metadata": {},
   "source": [
    "### Etapa 2: Limpagem e separação dos dados\n",
    "Retirada de linhas com dados nulos e separação dos dados de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9856233-1da1-41d1-9efc-be67aed04b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X_Train = df[(df.year >= 2022) & (df.year <= 2024)]\n",
    "X_Train = X_Train[(X_Train.year < 2024) | (X_Train.month <= 6)].reset_index(drop=True)\n",
    "Y_Train = X_Train[\"J_count\"]\n",
    "X_Train.drop(columns=[\"J_count\", \"region\"], inplace=True)\n",
    "\n",
    "X_Valid = df[(df.year == 2024) & (df.month >= 7)].reset_index(drop=True)\n",
    "Y_Valid = X_Valid[\"J_count\"]\n",
    "X_Valid.drop(columns=[\"J_count\", \"region\"], inplace=True)\n",
    "\n",
    "X_Test = df[df.year == 2025].reset_index(drop=True)\n",
    "Y_Test = X_Test[\"J_count\"]\n",
    "X_Test.drop(columns=[\"J_count\", \"region\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2f793-2e1c-4d64-96fc-f3bae4a46b9b",
   "metadata": {},
   "source": [
    "### Etapa 3: Modelo Base\n",
    "Testes usando modelo de Regressão Linear, implementada pelo scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf18618-c6f7-453c-8424-7767045eac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sk.linear_model.LinearRegression().fit(X_Train, Y_Train)\n",
    "\n",
    "val_resul = model.predict(X_Valid)\n",
    "test_resul = model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6141b-5337-4cc7-96b5-795de2706c27",
   "metadata": {},
   "source": [
    "### Etapa 4: Modelo LightGBM\n",
    "\n",
    "Testes usando modelo com objetivo Poisson, implementada pelo lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb854e33-d5cc-4308-863a-352b5892d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24420\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score 3.504180\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's poisson: -91.2195\n"
     ]
    }
   ],
   "source": [
    "seed = 778\n",
    "\n",
    "lgb_train = lgb.Dataset(X_Train, Y_Train)\n",
    "lgb_valid = lgb.Dataset(X_Valid, Y_Valid)\n",
    "\n",
    "\n",
    "model = lgb.train(params={\"objective\": \"poisson\"}, train_set=lgb_train, valid_sets=lgb_valid, callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "\n",
    "res_pred = model.predict(X_Test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a299c-d35d-4b29-a5b1-7407fc26bf8f",
   "metadata": {},
   "source": [
    "### Etapa 5: Métricas\n",
    "\n",
    "Comparação dos resultados de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5194fb-b451-4d06-a533-dd8ab3d9ec0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m df_resultados[\u001b[33m\"\u001b[39m\u001b[33mBase resultados\u001b[39m\u001b[33m\"\u001b[39m] = test_resul\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df_resultados[\u001b[33m\"\u001b[39m\u001b[33mLightGBM resultados \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(i)] = \u001b[43mi_res\u001b[49m[i]\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgraf_resultado\u001b[39m(titulo, metrica, valor_base, valor_lgb):\n\u001b[32m     10\u001b[39m     fig = plt.figure()\n",
      "\u001b[31mNameError\u001b[39m: name 'i_res' is not defined"
     ]
    }
   ],
   "source": [
    "df_resultados = X_Test[[\"month\", \"CNES\", \"hospital_porte\"]]\n",
    "df_resultados[\"year\"] = 2025\n",
    "df_resultados = df_resultados[[\"year\", \"month\", \"CNES\", \"hospital_porte\"]]\n",
    "df_resultados[\"Valor Real\"] = Y_Test\n",
    "df_resultados[\"Base resultados\"] = test_resul\n",
    "for i in range(5):\n",
    "    df_resultados[\"LightGBM resultados \" + str(i)] = i_res[i]\n",
    "\n",
    "def graf_resultado(titulo, metrica, valor_base, valor_lgb):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(10)\n",
    "    \n",
    "    w, x = 0.4, np.arange(1)\n",
    "    bars1 = plt.bar(x - w/2, [valor_base], w, label=\"Modelo Base\")\n",
    "    bars2 = plt.bar(x + w/2, [valor_lgb], w, label=\"LightGBM\")\n",
    "    plt.bar_label(bars1)\n",
    "    plt.bar_label(bars2)\n",
    "    plt.xticks(x, [\"\"])\n",
    "    plt.ylabel(metrica)\n",
    "    plt.title(titulo)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# MAE\n",
    "base_mae = mean_absolute_error(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_mae_ar = []\n",
    "for i in range(5):\n",
    "    lgb_mae_ar.append(mean_absolute_error(y_true=Y_Test, y_pred=i_res[i]))\n",
    "lgb_mae = np.mean(lgb_mae_ar)\n",
    "\n",
    "# RMSE\n",
    "base_rmse = mean_squared_error(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_rmse_ar = []\n",
    "for i in range(5):\n",
    "    lgb_rmse_ar.append(mean_squared_error(y_true=Y_Test, y_pred=i_res[i]))\n",
    "lgb_rmse = np.mean(lgb_rmse_ar)\n",
    "\n",
    "# SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "base_smape = smape(y_true=Y_Test, y_pred=test_resul)\n",
    "lgb_smape_ar = []\n",
    "for i in range (5):\n",
    "    lgb_smape_ar.append(smape(y_true=Y_Test, y_pred=i_res[i]))\n",
    "lgb_smape = np.mean(lgb_smape_ar)\n",
    "\n",
    "# Graficos\n",
    "graf_resultado(\"MAE por Modelo\", \"MAE\", base_mae, lgb_mae)\n",
    "graf_resultado(\"RMSE por Modelo\", \"RMSE\", base_rmse, lgb_rmse)\n",
    "graf_resultado(\"sMAPE por Modelo\", \"sMAPE\", base_smape, lgb_smape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
